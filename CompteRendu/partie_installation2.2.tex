\section{Hadoop 2.2}
\label{sec:hadoop-2.2}

\par A partir des versions , Hadoop vient avec un nouveau composant appelé Yarn. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=12cm]{images/yarn.png}
  \caption{Différences entre Hadoop 1.x et Hadoop 2.x}
  \label{fig:yarn}
\end{figure}

Yarn est responsable de la gestion des ressources, et utilise des processus similaires pour leur gestion. Le NodeManager vient remplacer le TaskTracker, qui s'occupe de faire le lien entre le DataNode et le ResourceManager localisé sur le master (NameNode). Le ResourceManager déploie les applications sur les noeuds grâce à sa communication avec les NodeManagers.

\subsection{Connexion sur un ordinateur à Supélec}
\label{sec:connexion-sur-un}

\par La connexion avec un compte utilisateur précis est particulière, dans la mesure où on peut accéder à son dossier personnel, correspondant à des identifiants de connexion, depuis n'importe quelle machine. En effet, une machine est responsable de la gestion des logins, et contient les données personnelles correspondantes. Ces données transitent lors d'une connexion, ce qui peut faire croire que ces données sont présentes sur tous les ordinateurs.

\par Il est important de garder à l'esprit ce mécanisme, car c'est grâce à celui-ci que nous pourront simplifier la configuration de Hadoop sur le cluster Skynet. Malgré ces données qui ne sont pas propres à une machine, nous devons également pouvoir accéder à la mémoire de la machine physique, afin de pouvoir les utiliser comme DataNodes. Dans un premier temps, nous utiliserons le dossier \texttt{/tmp} accessible en lecture écriture à n'importe qui (donc peu sécurisé, mais adapté à notre installation de test).

\begin{figure}[h!]
  \centering
  \includegraphics[width=16cm]{images/connexion_supelec.png}
  \caption{Exemple d'une connexion sur une machine quelconque}
  \label{fig:connexion_supelec}
\end{figure}

\subsection{Connexion SSH}
\label{sec:connexion-ssh}

\par Lors d'une connexion SSH, le fichier \texttt{.bash\_profile} est exécuté. Lors d'un login, c'est le fichier \texttt{.bashrc} qui est exécuté. Comme toutes les connexions via hadoop se font par ssh, nous allons les lier tous les deux. Pour cela, on créera un fichier \texttt{.bash\_profile} contenant au moins :

\begin{minted}[frame=single,linenos,mathescape]{bash}
  if [ -f .bashrc ]; then
    . ~/.bashrc
  fi
\end{minted}

\par De cette manière, si le fichier \texttt{.bashrc} existe, on le charge, sinon on ne fait rien.
\par On se connecte successivement sur \texttt{Ghome}, puis \texttt{Term2} :
\begin{minted}[frame=single,mathescape]{bash}
  Alex > ssh ghome
  Last login: Sat Jun 14 22:00:38 2014 from 193.48.225.99
  Alex [gserver] > ssh term2
  Last login: Sat Jun 14 20:52:34 2014 from gserver.grid.metz.supelec.fr
  Alex [term2] > 
\end{minted}

\par A partir de \texttt{Term2}, on peut se connecter à chacune des machines du cluster Skynet, dont les alias permettent de simplifier les opérations. Ainsi au lieu de 

\begin{minted}[frame=single]{bash}
  ssh careil_ale@term2.grid.metz.supelec.fr
\end{minted}
 on peut simplement faire
\begin{minted}[frame=single]{bash}
  ssh careil_ale@term2
\end{minted}

car nous sommes dans le domaine \texttt{grid.metz.supelec.fr}.

 Il est inutile de spécifier le nom d'utilisateur lors de la connexion puisque, comme expliqué précédemment, notre compte existe sur toutes les machines (pas physiquement, mais il est chargé à chaque fois). Donc au lieu de se connecter avec la commande précédente, on peut simplement faire :
 
\begin{minted}[frame=single]{bash}
  ssh term2
\end{minted}

Cependant, il faut effectuer une manoeuvre afin de pouvoir se connecter facilement sans mot de passe. En effet, on va générer une clé SSH avec la commande \texttt{ssh-keygen} (qu'on appellera \texttt{id\_rsa\_test}). Vu qu'on ne veut pas utiliser de mot de passe pour se connecter, on omettra la \texttt{Passphrase} lors de la création de la clé.

\begin{minted}[frame=single]{bash}
Alex > ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/home/alexandre/.ssh/id_rsa): 
id_rsa_test
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in id_rsa_test.
Your public key has been saved in id_rsa_test.pub.
The key fingerprint is:
61:e0:38:43:34:aa:fc:7b:6e:e3:04:79:a2:f6:14:1a alexandre@gentooalex
The key's randomart image is:
+--[ RSA 2048]----+
|   .+ .          |
|   o + .         |
|  . + . o        |
|..  .o . .       |
|.E = .  S        |
|  = =            |
| + o .           |
|. o o+           |
|   o=o.          |
+-----------------+
\end{minted}

\par Maintenant, allons dans le dossier \texttt{.ssh} contenant notre clé publique, et notre clé privée afin de créer le fichier \texttt{authorized\_keys} s'il n'existe pas déjà. S'il n'existe pas, tapez la commande \texttt{touch authorized\_keys} afin de le créer.

\par On va ajouter notre clé publique à l'ensemble des clés autorisées :
\begin{minted}[frame=single]{bash}
cat id_rsa_test.pub >> authorized_keys
\end{minted}
\par On peut désormais vérifier que cela fonctionne bien en se connectant par exemple à \texttt{sh00}. Normalement, aucun mot de passe n'est demandé. 

\par Un dernier problème peut empêcher une connexion directe en ssh, celui de la vérification d'authenticité de l'hôte sur lequel on veut se connecter : 
\begin{minted}[frame=single]{bash}
Juan [master] > ssh munozperez_jua@ghomE.metz.supelec.fr
The authenticity of host 'ghome.metz.supelec.fr (193.48.224.129)' 
can't be established.
RSA key fingerprint is c1:41:c3:6d:f1:21:a2:2a:e6:30:b0:60:f7:de:22:b1.
Are you sure you want to continue connecting (yes/no)? YES
Warning: Permanently added 'ghome.metz.supelec.fr,193.48.224.129' 
(RSA) to the list of known hosts.
\end{minted}

\par Pour enlever ce message, il faut se connecter manuellement à chaque noeud pour qu'il soit ajouté à la liste des hôtes connus (listés dans le fichier \texttt{~/.ssh/known\_hosts}).

\subsection{Hadoop avec OAR}
\label{sec:hadoop-avec-oar}

\par On prévoit d'utiliser Hadoop avec OAR. C'est-à-dire qu'une fois connecté sur \texttt{Term2}, on effectue une requête \texttt{OAR} en intéractif afin de commander des noeuds sur le cluster (Skynet dans notre cas). Si la requête se solde par un succès, une session est ouverte (une connexion ssh...) sur le noeud qui va nous permettre de les utiliser tous.

\par Ce n'est qu'une fois la session lancée qu'on peut commencer à configurer Hadoop ! D'où l'intérêt d'automatiser la génération de ces fichiers en fonction de la session, des noeuds commandés... 
\par Typiquement, le noeud sur lequel on arrive sera le \texttt{NameNode}, et générera les fichiers de configuration pour tous les noeuds (master et slave).

\par Pour générer les fichiers de configuration de manière automatisée, on va créer des fichiers contenant des variables telles que le nom du \texttt{NameNode} (que l'on connaît grâce à la variable \texttt{HADOOP\_NAMENODE\_NAME} par exemple). Ces fichiers seront placés dans un dossier \texttt{hadoop\_conf\_original}, et permettront de générer à chaque session \texttt{OAR} des fichiers de configuration adaptés à la session en cours (avec le nom du \texttt{NameNode}, \texttt{SecondaryNameNode}...). Grâce à la variable \texttt{OAR\_FILE\_NODE}, on obtient le nom des machines que l'on a réservées avec \texttt{OAR}.

\newpage

\subsection{Génération des fichiers de configuration de Hadoop grâce au \texttt{.bashrc}}
\label{sec:creat-des-fich}

\par Ce fichier va nous permettre d'instancier des variables d'environnement utiles pour Hadoop au moment d'une connexion SSH. Comme expliqué précédemment, c'est le fichier \texttt{.bash\_profile} qui est chargé, mais nous ferons en sorte que ce dernier fasse appel au \texttt{.bashrc}, dont nous allons donc détailler le contenu.

\paragraph{Variables d'environnement utilisées par Hadoop}
\label{sec:vari-denv-util}

\begin{minted}[frame=single,linenos,mathescape]{bash}
export JAVA_HOME=/usr/lib/jvm/java

# Hadoop
HADOOP_PREFIX=/opt/hadoop-2.2.0
export HADOOP_HOME=$HADOOP_PREFIX
export HADOOP_COMMON_HOME=$HADOOP_PREFIX
export HADOOP_HDFS_HOME=$HADOOP_PREFIX
export HADOOP_MAPRED_HOME=$HADOOP_PREFIX
export HADOOP_YARN_HOME=$HADOOP_PREFIX
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_PREFIX}"/lib/native/"
export HADOOP_OPTS="${HADOOP_OPTS}
 -Djava.library.path=$HADOOP_PREFIX/lib/"

export HADOOP_CONF_DIR=~/hadoop_conf
export HADOOP_LOG_DIR=~/hadoop_logs
export HADOOP_NAMENODE_NAME=localhost
\end{minted}

\par Dans cette première partie, nous définissons la variable \texttt{JAVA\_HOME} nécessaire pour localiser la machine virtuelle Java à utiliser pour exécuter Hadoop, qui, rappelons le, est codé en Java. Généralement, sous Linux, le chemin à mettre est très simple, car il s'agit d'un lien symbolique (l'adresse ne pointe donc pas directement sur la bonne version de Java à utiliser, mais sur un "fichier lien" qui pointe sur la version actuelle de Java utilisée sur le système).

\par \texttt{HADOOP\_PREFIX} est une variable "maison" nous permettant de ne spécifier le chemin vers Hadoop une seule fois. De cette manière, si on devait changer Hadoop d'emplacement, la modification de cette variable seule nous permettrait de modifier toutes les autres. Elle n'est donc pas utilisée par Hadoop.

\par \texttt{HADOOP\_HOME}, \texttt{HADOOP\_COMMON\_HOME},
\texttt{HADOOP\_HDFS\_HOME}, \texttt{HADOOP\_MAPRED\_HOME}, \\ \texttt{HADOOP\_YARN\_HOME}, sont les variables de base, spécifiant les chemins vers les divers composants de Hadoop. Dans notre cas, l'installation simple réunit tous les composants au même endroit, mais ce n'est pas tout le temps le cas. On les fixe donc toutes à \texttt{HADOOP\_PREFIX}.

\par La variable \texttt{PATH} est utilisée par le Shell (bash dans notre cas) afin de faire correspondre chaque commande tapée avec un programme localisé dans un des dossiers spécifiés dans cette variable. Par défaut, on a généralement \texttt{PATH=/usr/local/bin:/usr/bin:/bin}, car les programmes installés par défaut (de type interne comme par exemple \texttt{ls}, \texttt{cat}... ) sont installés dans \texttt{/bin}. Ceux installés par l'utilisateur sont localisés dans \texttt{/usr/bin}. Les programmes nécessitant des privilèges administrateurs pour être exécutés sont dans \texttt{/usr/sbin}, et ce dossier n'est ajouté à la variable \texttt{PATH} que lorsqu'on est connecté avec le compte administrateur \texttt{root}.

\par Les variables \texttt{HADOOP\_OPTS} et \texttt{HADOOP\_COMMON\_LIB\_NATIVE} permettent de spécifier respectivement le dossier dans lequel Java doit aller chercher les librairies (compilées car écrites en \texttt{C}), et le dossier contenant les librairies natives (ces mêmes librairies, mais compilées spécifiquement pour la machine sur laquelle Hadoop est exécuté).

\par \texttt{HADOOP\_CONF\_DIR} permet de spécifier l'emplacement des fichiers de configuration de Hadoop, chose très importante dans notre cas puisque nous les localisons dans notre espace personnel, afin qu'ils soient accessibles à chaque connexion ssh, quelque soit la machine.

\par \texttt{HADOOP\_LOG\_DIR} redéfinit par défaut le dossier dans lequel les logs relatifs aux composants Hadoop (\texttt{NameNode}, \texttt{SecondaryNameNode} et \texttt{DataNode} sont stockés. Il est indispensable de les localiser sur notre espace personnel (\texttt{~/.}), d'une part pour des questions de droits d'écriture, car le dossier \texttt{/opt/hadoop-2.2.0} n'est actuellement pas accessible en écriture pour les utilisateurs lambda, et d'autre part car si plusieurs utilisateurs venaient à utiliser Hadoop, les logs générés seraient alors centralisés, et rendrait leur consultation difficile.

\par La dernière variable de cet extrait de \texttt{.bashrc} est une variable qui nous sera utile par la suite. \texttt{HADOOP\_NAMENODE\_NAME} contient en fait le nom de la machine qui fait office de NameNode.

\paragraph{Configuration du prompt}
\label{sec:conf-du-prompt}

\par La configuration du prompt va nous permettre de naviguer plus efficacement de machine en machine. En effet, par défaut, le prompt ressemble à \texttt{bash4.2\$ }, ce qui n'est pas très utile en soit. Il serait plus intéressant d'avoir le nom d'hôte de la machine sur laquelle on est connecté.


\begin{minted}[frame=single,linenos,mathescape]{bash}
case "$TERM" in
"dumb")
    export PS1="> "
    ;;
xterm*|rxvt*|eterm*|screen*)
    export PS1='\[\033[00;32m\]Alex [\h] > \[\033[00m\]'
    ;;
*)
    export PS1="> "
    ;;
esac
\end{minted}

\par La variable d'environnement \texttt{TERM} permet de spécifier le type de terminal utilisé. Chaque émulateur de terminal initialise cette variable selon son nom généralement. Par exemple, si on utilise \texttt{xterm}, on aura \texttt{TERM=xterm}. 
\par Changer le prompt peut nous faciliter la vie lorsqu'on utilise un terminal comme \texttt{xterm} ou \texttt{rxvt}, mais on peut par exemple utiliser un autre logiciel qui se connecte en ssh en parsant le prompt, comme l'extension \texttt{TRAMP} d'Emacs. Si le prompt est différent de \texttt{ >}, la connexion sera impossible. Et plus généralement, il vaut mieux garder un prompt simple et standard pour toutes les autres utilisations potentielles. C'est ainsi que notre \texttt{switch} intervient. Selon la valeur la valeur de \texttt{TERM}, on redéfinit la variable \texttt{PS1} qui contient le prompt de manière plus ou moins standard.

\paragraph{Construction du NameNode}
\label{sec:constr-du-namen}

\par Une fois la requête \texttt{OAR} effectuée, nous arrivons sur un noeud sur lequel des variables d'environnement \texttt{OAR} sont instanciées. C'est de cette manière qu'on identifiera le \texttt{NameNode}, car les autres noeuds n'ont pas ces variables.

\begin{minted}[frame=single,linenos,mathescape]{bash}
if [ ! -d "/tmp/hadoop-tmp" ]; then mkdir /tmp/hadoop-tmp; fi
if [ ! -d "/tmp/hadoop-tmp/hdfs" ]; then mkdir /tmp/hadoop-tmp/hdfs; fi
if [ ! -d "/tmp/hadoop-tmp/hdfs/datanode" ]; then
    mkdir /tmp/hadoop-tmp/hdfs/datanode;
fi
# Si on est sur le NameNode
if [ -n "$OAR_FILE_NODES" ]; then
    if [ ! -d "/tmp/hadoop-tmp/hdfs/namenode" ]; then
        mkdir /tmp/hadoop-tmp/hdfs/namenode;
    fi
    if [ ! -d "/tmp/hadoop-tmp/hdfs/namesecondary" ]; then
        mkdir /tmp/hadoop-tmp/hdfs/namesecondary;
    fi
    
    # Si le dossier de configuration n'existe pas on le crée
    if [ ! -d "$HADOOP_CONF_DIR" ]; then 
        mkdir $HADOOP_CONF_DIR;
    # sinon on le vide
    else rm -f $HADOOP_CONF_DIR"/*";
    fi
    if [ ! -d $HADOOP_CONF_DIR"_slaves" ]; then
	mkdir $HADOOP_CONF_DIR"_slaves";
    else rm -f $HADOOP_CONF_DIR"_slaves/*";
    fi

    # Définition du nom du Namenode
    export HADOOP_NAMENODE_NAME=$(head -1 $OAR_FILE_NODES);
    for f in ~/hadoop_conf_original/*; do
	cat $f | sed 
        -e 's/\$HADOOP_NAMENODE_NAME/'$HADOOP_NAMENODE_NAME'/g' 
        > ~/hadoop_conf/$(basename $f);
    done;
    cat $OAR_FILE_NODES | uniq > $HADOOP_CONF_DIR/slaves;
    for f in ~/hadoop_conf_slaves_original/*; do
	cat $f | sed 
        -e 's/\$HADOOP_NAMENODE_NAME/'$HADOOP_NAMENODE_NAME'/g'
	> ~/hadoop_conf_slaves/$(basename $f);
    done;
else
    export HADOOP_CONF_DIR=~/hadoop_conf_slaves;
fi
\end{minted}

\par Expliquons donc ce gros morceau de code \texttt{bash}. On commence par créer s'ils n'existent pas, les dossiers sur la machine physique qui vont permettre de stocker les données. On suppose que toute machine est un \texttt{DataNode}, donc on créera d'abord le dossier \texttt{/tmp/hadoop-tmp}, puis dedans on créera un dossier \texttt{hdfs}, avant de finalement créer le dossier \texttt{datanode} qui contiendra les données du \texttt{DataNode}.
\par Si on se connecte sur le \texttt{NameNode}, ce que l'on sait en vérifiant l'existence de la variable \texttt{OAR\_NODE\_FILE}, on ajoute deux dossiers supplémentaires \texttt{namenode} et \texttt{namesecondary}, respectivement pour le \texttt{NameNode} et le \texttt{SecondaryNameNode}.
\par Une fois ces dossiers créés sur la machine physique (c'est-à-dire que si on se connecte sur une autre machine, ces dossiers n'apparaîtront pas), on crée les dossiers sur l'espace personnel qui vont accueillir les fichiers de configuration générés. Donc s'ils n'existent pas, on crée les dossiers \texttt{hadoop\_conf} et \texttt{~/hadoop\_conf\_slaves}, et s'ils existent déjà, c'est qu'ils ont probablement déjà accueilli des fichiers de configuration lors d'une précédente session \texttt{OAR}, dans ce cas on les vide.
\par Dernière étape, lors de la connexion sur le \texttt{NameNode}, on génère les fichiers de configuration qui vont être utilisés !
Pour cela, on redéfinit la variable \texttt{HADOOP\_NAMENODE\_NAME} en prenant le premier nom d'hôte dans la liste des hôtes fournis, accessible via la commande \texttt{cat \$OAR\_FILE\_NODE}. En fait, les variables \texttt{bash} ne sont pas évaluées dans les fichiers de configuration \texttt{xml} de Hadoop, d'où la nécessité d'en générer de nouveaux, avec les références au \texttt{NameNode} en dur. On crée donc chaque fichier à partir de son original, aussi bien pour \texttt{hadoop\_conf} que pour \texttt{hadoop\_conf\_slaves}, en remplaçant \texttt{HADOOP\_NAMENODE\_NAME} par sa valeur. Pour le dossier \texttt{hadoop\_conf}, on met à jour le fichier \texttt{slaves} grâce au contenu du fichier désigné par la variable \texttt{OAR\_FILE\_NODE}.

\par Pour finir, si on se connecte sur un autre noeud que le \texttt{NameNode}, en supposant qu'il s'agisse d'un noeud qui ne possède pas de variables d'environnement \texttt{OAR}, on change simplement la variable \texttt{HADOOP\_CONF\_DIR} afin qu'elle pointe vers les fichiers de configuration du dossier \texttt{hadoop\_conf\_slaves}, spécifiques aux machines esclaves. Nous concernant, à part le fichier \texttt{slaves} qui diffère entre les deux dossiers, tous les autres fichiers sont identiques, il ne s'agit donc que d'une pure précaution dans le cas où il faudrait spécifier des configurations différentes pour les maîtres et les esclaves.

\paragraph{Précautions lors de la déconnexion}
\label{sec:precautions-lors-de}

\par Lorsque sur une session \texttt{OAR} les services Hadoop sont démarrés, il est dangereux de se déconnecter sans les arrêter. Arrêter la session \texttt{OAR} avant d'avoir arrêté Hadoop mène tout droit à un encombrement des ports. En effet, chaque composant de Hadoop utilise un port spécifié dans les fichiers de configuration, et si on quitte la session \texttt{OAR} avant d'arrêter les services, ceux-ci restent occupés et cela empêche Hadoop de se lancer correctement la fois suivante (sauf si les machines ont subi un reboot entre temps).

\par On se propose, pour éviter toute déconnexion hasardeuse lorsque des services seraient encore actifs, d'afficher un message de confirmation au moment de la déconnexion. Ce message ne s'afficherait que si le nombre de processus Java lancés est supérieur ou égal à 1. On voit les processus grâce à la commande \texttt{jps}. Cette commande retourne au moins une ligne, correspondant au processus \texttt{Jps}. Si le nombre de lignes retournées par cette commande est strictement supérieur à 1, il y a des processus Java lancés, et le message de confirmation s'affiche.

\par Pour ce faire, on utilise une fonction auxiliaire (dont l'idée appartient à un bloggeur) \texttt{confirm} qui retourne une erreur \texttt{1} si on ne répond pas \texttt{yes}, et bloque la suite des opérations. En combinant cette fonction avec la commande \texttt{exit}, à l'aide de l'opérateur \texttt{&&}, si la fonction \texttt{confirm} ne s'exécute pas correctement (si on n'a pas répondu \texttt{yes}), la commande placée après ne s'exécute pas.
\begin{verbatim}
confirm Logout ? && exit;
\end{verbatim}

\par En ayant connaissance de cette astuce, on crée donc la fonction \texttt{testExit} qui va tester le nombre de lignes retournées par \texttt{jps}, et on le prend supérieur strictement à 1. Sinon on ne met pas de message de confirmation.
\begin{minted}[frame=single,linenos,mathescape]{bash}
function confirm()
{
    echo -n "$@ "
    read -e answer
    for response in y Y yes YES Yes Sure sure SURE OK ok Ok
    do
        if [ "_$answer" == "_$response" ]
        then
            return 0
        fi
    done
 
    # Any answer other than the list above is considerred a "no" answer
    return 1
}

function testExit()
{
    if [[ "$(jps|wc -l)" -gt "1" ]]; then
    confirm Avez-vous bien arrêté tous les processus Java ? 
    \(commande jps\) yes/no && logout;
    else
	logout;
    fi
}

alias exit="testExit";
\end{minted}

\par Note concernant l'utilisation de \texttt{logout} : on n'utilise pas la fonction \texttt{exit} dans la déclaration de \texttt{testExit}, car l'idée est de définir exit comme alias de cette fonction. Donc si on appelait \texttt{exit} dans \texttt{testExit}, elle s'appellerait à l'infini, d'où l'astuce du \texttt{logout}.

\par Pour continuer dans la lignée des améliorations, on remarquera que l'appel de la fonction \texttt{exit} dans notre fonction \texttt{testExit} n'est autre que la fonction \texttt{builtin exit}, qui est la fonction prédéfinie (qualifiée d'interne) et faisant partie intégrante du Shell \texttt{bash}. Une méthode plus propre aurait donc été de redéfinir la fonction \texttt{exit} à partir de la fonction interne du même nom.
\par Rappelons au passage qu'il existe deux types de fonctions lorsqu'on utilise un Shell : les fonctions internes, et les fonctions externes. Les fonctions internes font partie de l'ensemble des fonctions fournies avec le Shell (\texttt{bash} dans notre cas), alors que les fonctions externes sont les fonctions accessibles du fait de l'installation de programmes tiers. Par exemple, la fonction \texttt{hdfs} est une commande externe, alors que \texttt{ls} est une fonction interne. En spécifiant \texttt{builtin ls}, on fait appel à la fonction de base fournie avec le logiciel \texttt{bash}.
\par Conclusion, au lieu d'avoir une fonction \texttt{testExit} qu'on utilise pour un alias de la fonction \texttt{exit}, redéfinissons simplement la fonction \texttt{exit} à partir de sa version interne :

\begin{minted}[frame=single,linenos,mathescape]{bash}
function exit()
{
    if [[ "$(jps|wc -l)" -gt "1" ]]; then
	confirm Avez-vous bien arrêté tous les processus Java ?
        \(commande jps\) yes/no && builtin exit;
    else
	builtin exit;
    fi
}
\end{minted}

\subsection{Contenu des fichiers de configuration de Hadoop}
\label{sec:contenu-des-fichiers}

\par Venons-en maintenant aux fichiers qui vont permettre la génération des fichiers de configuration finals, spécifiques de la session \texttt{OAR}. Ces fichiers ont quasiment la même utilité que pour les versions précédentes de Hadoop, seules les propriétés peuvent avoir changé de nom (par exemple, un "\texttt{\_}" peut avoir été changé en "\texttt{.}" pour certaines propriétés, semant la confusion chez ceux qui tentent de configurer Hadoop correctement...)

\subsubsection{\texttt{core-site.xml}}
\label{sec:core-site.xml}

\par Dans ce fichier, nous configurons les paramètres généraux de HDFS et de Hadoop en général. Nous retrouverons ainsi la localisation du dossier temporaire sur la machine pour y stocker les fichiers temporaires générés lors de manipulations diverses. Egalement, \texttt{fs.default.name} est la variable spécifiant l'adresse à laquelle on effectue les demandes au système de fichiers distribué HDFS.
\par On ne met pas le nom d'une machine en dur, car comme expliqué précédemment, la variable \texttt{\$HADOOP\_NAMENODE\_NAME} sera remplacée par le nom de la machine qui hébergera le \texttt{NameNode}, nom dépendant de la session \texttt{OAR}.

\par Notons enfin que \texttt{9100} est un port qui doit être libre sur la machine accueillant le \texttt{NameNode}.

\begin{minted}[mathescape,frame=single,linenos]{xml}
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/tmp/hadoop-tmp</value>
    <description>A base for other temporary directories.</description>
  </property>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://$HADOOP_NAMENODE_NAME:9100/</value>
  </property>
</configuration>
\end{minted}

\subsubsection{\texttt{hdfs-site.xml}}
\label{sec:hdfs-site.xml-1}

\par Ce dossier est spécifique du système de fichiers HDFS. Il permet de régler la localisation des espaces de stockage pour les \texttt{NameNode}, \texttt{SecondaryNameNode}, \texttt{DataNode} sur les machines physiques. Il permet également de spécifier le taux de réplication des données sur l'espace distribué (qui correspond au nombre de fois qu'un fichier est stocké de manière répartie sur les \texttt{DataNodes}.

\par Nous prenons soin de déterminer les adresses d'accès aux \texttt{DataNodes}, \texttt{NameNode} et \texttt{SecondaryNameNode} pour des raisons d'encombrement de ports, problème sur lequel nous reviendrons plus loin.

\begin{minted}[mathescape,frame=single,linenos]{xml}
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
    <description>Default block replication.
    The actual number of replications can be specified when 
    the file is created.
    The default of 3 is used if replication is not specified.
    </description>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/tmp/hadoop-tmp/hdfs/namenode</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:/tmp/hadoop-tmp/hdfs/datanode</value>
  </property>
  <property>
    <name>fs.checkpoint.dir</name>
    <value>file:/tmp/hadoop-tmp/hdfs/namesecondary</value>
  </property>

  <property>
    <name>dfs.datanode.address</name>
    <value>localhost:0</value>
  </property>
  <property>
    <name>dfs.namenode.http-address</name>
    <value>$HADOOP_NAMENODE_NAME:9001</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>$HADOOP_NAMENODE_NAME:4501</value>
  </property>
</configuration>
\end{minted}

\subsubsection{\texttt{mapred-site.xml}}
\label{sec:mapred-site.xml-1}

\begin{minted}[mathescape,frame=single,linenos]{xml}
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>${HADOOP_NAMENODE_NAME}:54311</value>
    <description>The host and port that the MapReduce job tracker runs
      at.  If "local", then jobs are run in-process as a single map
      and reduce task.
    </description>
  </property>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
\end{minted}

\subsubsection{\texttt{yarn-site.xml}}
\label{sec:yarn-site.xml}

\par Ce fichier est très important, car il permet de configurer \emph{Yarn}, le gestionnaire de ressources et déployeur d'applications de Hadoop dans ses versions récentes 2.x.
\par On laissera par défaut le \texttt{classpath} de \emph{Yarn}, ce qui nous épargnera bien des soucis. 

\par \texttt{yarn.nodemanager.aux-services.mapreduce\_shuffle.class} est la classe chargée d'effectuer le tri lors d'une application MapReduce (ce qui explique le fait que les entrées soient triées dans un ordre non aléatoire lors d'un wordcount par exemple).

\par L'adresse \texttt{0.0.0.0} représente l'adresse locale de la machine, elle permet à une machine de faire appel à son nodemanager lancé sur un port précis.

\begin{minted}[mathescape,frame=single,linenos]{xml}
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
     <name>yarn.nodemanager.aux-services</name>
     <value>mapreduce_shuffle</value>
  </property>
  <property>
     <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
     <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>
  <property>
    <name>yarn.dispatcher.exit-on-error</name>
    <value>true</value>
  </property>
  <property>
    <name>yarn.app.mapreduce.am.staging-dir</name>
    <value>/user</value>
  </property>

  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>$HADOOP_NAMENODE_NAME:8030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>$HADOOP_NAMENODE_NAME:8031</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>$HADOOP_NAMENODE_NAME:8032</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>$HADOOP_NAMENODE_NAME:8033</value>
  </property>
  <property>
    <name>yarn.web-proxy.address</name>
    <value>$HADOOP_NAMENODE_NAME:8034</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>$HADOOP_NAMENODE_NAME:8088</value>
  </property>
  <property>
    <name>yarn.nodemanager.address</name>
    <value>0.0.0.0:8050</value>
  </property>
    <property>
    <name>yarn.nodemanager.localizer.address</name>
    <value>0.0.0.0:8060</value>
  </property>
</configuration>
\end{minted}

\subsubsection{\texttt{capacity-scheduler.xml}}
\label{sec:capac-sched-site.xml}

\par Tout d'abord, commençons par souligner l'intérêt du nom des fichiers. En effet, certains tutoriels disponibles sur internet sont assez laxistes quant aux indications, et il s'est trouvé qu'un d'entre eux a indiqué que le présent fichier \texttt{capacity-scheduler.xml} s'appelait \texttt{capacity-scheduler-site.xml}, une erreur qui nous a coûté beaucoup de temps.

\begin{minted}[mathescape,frame=single,linenos]{xml}
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
    <value>0.1</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.root.queues</name>
    <value>default</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.root.default.capacity</name>
    <value>100</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
    <value>1</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.root.queues</name>
    <value>default</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
    <value>100</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.root.default.state</name>
    <value>RUNNING</value>
  </property>
  <property>
    <name>
      yarn.scheduler.capacity.root.default.acl_submit_applications
    </name>
    <value>*</value>
  </property>
  <property>
    <name>
      yarn.scheduler.capacity.root.default.acl_administer_queue
    </name>
    <value>*</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.node-locality-delay</name>
    <value>-1</value>
  </property>
</configuration>
\end{minted}

\subsubsection{\texttt{hadoop-env.sh} et \texttt{yarn-env.sh}}
\label{sec:hadoop-env.sh-et}

\par Ces deux fichiers permettent de déclarer des variables d'environnement utilisées par Hadoop. Pourquoi donc avoir remplacé les variables \texttt{\$HADOOP\_NAMENODE\_NAME} ? Puisque celles-ci auraient pu être simplement définies dans ces fichiers... Nous avons essayé, et cela n'a pas fonctionné. De même que le \texttt{classpath} de \emph{Yarn} était défini à l'aide de telles variables, ces variables n'étaient pas interprétées, ce qui se traduisait donc par une erreur lors du déploiement d'une application sur les noeuds.

\par \texttt{hadoop-env.sh} et \texttt{yarn-env.sh} sont exactement les mêmes fichiers dans notre cas.

\begin{minted}[mathescape,frame=single,linenos]{bash}
export HADOOP_HEAPSIZE="500"
export HADOOP_NAMENODE_INIT_HEAPSIZE="500"

export JAVA_HOME=/usr/lib/jvm/java

export HADOOP_HOME=/opt/hadoop-2.2.0
export HADOOP_CONF_DIR=~/hadoop_conf
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true

export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/"
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME"/lib/native/"

export HADOOP_COMMON_HOME=/opt/hadoop-2.2.0
export HADOOP_HDFS_HOME=/opt/hadoop-2.2.0
export HADOOP_MAPRED_HOME=/opt/hadoop-2.2.0
export HADOOP_YARN_HOME=/opt/hadoop-2.2.0
export HADOOP_LOG_DIR=~/hadoop_logs
export YARN_LOG_DIR=~/yarn_logs

export YARN_CONF_DIR=~/hadoop_conf
\end{minted}


\subsection{Lancement des services hadoop}
\label{sec:lanc-des-serv}

\par Démarrons désormais depuis zéro hadoop et tous ses composants.

\par Commençons par se connecter à \texttt{Ghome}, puis \texttt{Term2}

\begin{minted}[frame=single]{bash}
ssh careil_ale@ghome.metz.supelec.fr
\end{minted}

puis

\begin{minted}[frame=single]{bash}
ssh term2
\end{minted}

\par Lançons une session \texttt{OAR}, afin d'avoir des noeuds à disposition, et faire fonctionner Hadoop dessus.

\begin{minted}[frame=single]{bash}
oarsub -l nodes=4,walltime=01:00:00 -I
\end{minted}

\par Nous avons donc quatre noeuds, et nos fichiers de configuration hadoop ont été générés dans \texttt{hadoop\_conf}.

\par Formattons le namenode (il faudra le faire à chaque fois qu'on démarrera une nouvelle session \texttt{OAR}, les noeuds alloués étant en théorie différents à chaque fois).
\begin{minted}[frame=single]{bash}
hdfs namenode -format
\end{minted}

\par Ceci fait, démarrons tous les services hadoop à l'aide du script prévu à cet effet :
\begin{minted}[frame=single]{bash}
start-all.sh
\end{minted}

\par Normalement, tous les services ont été lancés, les \texttt{DataNodes} et \texttt{NodeManagers} sont lancés sur tous les noeuds esclaves.

\par Construisons un dossier dans HDFS, afin de pouvoir y stocker nos données :

\begin{minted}[frame=single]{bash}
hdfs dfs -mkdir -p /user/careil_ale
\end{minted}

\par Copions-y un fichier texte

\begin{minted}[frame=single]{bash}
hdfs dfs -copyFromLocal ~/texte.txt /user/careil_ale/input
\end{minted}

\par Appliquons le wordcount dessus :

\begin{minted}[frame=single]{bash}
hadoop jar 
$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar 
wordcount input outputWordCount
\end{minted}

\par Pour visualiser le résultat, récupérer les fichiers générés depuis HDFS :

\begin{minted}[frame=single]{bash}
hdfs dfs -copyToLocal 
/user/careil_ale/outputWordCount/part* 
~/outputWordCount_texte.txt
\end{minted}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "CompteRendu"
%%% End: 
