\section{Hadoop 1.2.1}
\subsection{Préparation d'Hadoop}

\par Toutes les versions de Hadoop sont téléchargeables sur le site de la fondation Apache. Cependant il est préférable de travailler avec des versions stables. C'est notamment le cas pour les versions 1.2.x, 2.2.x et 2.3.x. L'installation en \emph{Single-Node} est réalisée avec la version 1.2.1.

\par Sur le lien ci-dessous, téléchargez le fichier \texttt{hadoop-1.2.1.tar.gz}  (61 Mb) :\\
\emph{http://apache.mirrors.multidist.eu/hadoop/common/hadoop-1.2.1/}

\par Une fois téléchargé, décompressez-le, renommez-le en hadoop et placez-le dans \texttt{/usr/local}. Il est de plus très important de changer le propriétaire ainsi que les droits de ce fichier :

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ cd /Users/hduser/Downloads
ThiDiff:~ hduser$ mv hadoop-1.2.1 hadoop
ThiDiff:~ hduser$ mv hadoop /usr/local
ThiDiff:~ hduser$ sudo chown hduser hadoop
\end{minted}

\par Vérifiez que le nouveau propriétaire du fichier hadoop est bien l'utilisateur \texttt{hduser} :

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ cd /usr/local
ThiDiff:local hduser$ ls -lisa | grep hadoop
26284444  0 drwxr-xr-x@  29 hduser   admin    986  3 mai 14:12 hadoop
\end{minted}

\par Une fois téléchargé, il faut désormais configurer les fichiers propres à Hadoop. Par conséquent, on ne parle par d'installation mais plutôt de configuration car il s'agit tout au long de définir les bonnes propriétés.

\subsection{Débriefing du dossier hadoop}

\par Le dossier \texttt{hadoop} contient de nombreux sous-dossiers qui ne sont pas tous aussi utiles les uns que les autres. En voici la liste :

\begin{verbatim}
CHANGES.txt
LICENSE.txt
NOTICE.txt
README.txt
bin
build.xml
c++
conf
docs
hadoop-ant-1.2.1.jar
hadoop-client-1.2.1.jar
hadoop-core-1.2.1.jar
hadoop-examples-1.2.1.jar
hadoop-minicluster-1.2.1.jar
hadoop-test-1.2.1.jar
ivy.xml
lib
libexec
sbin
share
src
\end{verbatim}

\par Nous ne nous attardons que sur les dossiers \texttt{bin} et \texttt{conf} qui se sont montrés essentiels lors de notre étude d'Hadoop, laissant ainsi le lecteur s'intéresser de plus près aux autres fichiers et dossiers.

\par A titre anecdotique, les fichiers \texttt{hadoop-*.jar} contiennent les librairies nécessaires à la compilation et à l'exécution des exemples contenus notamment dans le fichier \texttt{hadoop-exam\\ples-1.2.1.jar} (WordCount, Pi, etc...).

\par Ci-dessous les deux fichiers contenus dans le dossier \texttt{bin} que vous serez amenés à utiliser sans cesse dans le lancement des services Hadoop.

\begin{verbatim}
start-all.sh
stop-all.sh			
\end{verbatim}

\par Ces scripts shell vont permettent de lancer ou d'arrêter simultanément les différents démons d'Hadoop à savoir : le \texttt{NameNode} (NN), le \texttt{SecondaryNameNode} (SNN), le \texttt{DataNode} (DN), le \texttt{JobTracker} (JT) et le \texttt{TaskTracker} (TT). Pour de plus amples détails référez-vous à la partie \ref{sec:hdfs} détaillant les trois principaux démons HDFS. De plus il est possible de lancer au fur et à mesure les démons à l'aide des autres scripts :

\begin{verbatim}
start-dfs.sh
start-mapred.sh

stop-dfs.sh
stop-mapred.sh
\end{verbatim}

\par Le script \texttt{start-dfs.sh} lance les démons propre à HDFS alors que \texttt{start-mapred.sh} ceux propre à MapReduce, c'est-à-dire le \texttt{JobTracker} et le \texttt{TaskTracker}.

\par Le dossier \texttt{conf} est le plus important puisqu'il contient les fichiers de configuration de Hadoop. Quatre fichiers détaillés par la suite sont placés au premier plan :

\begin{verbatim}
hadoop-env.sh
core-site.xml
mapred-site.xml
hdfs-site.xml
\end{verbatim}

\subsection{Le fichier \texttt{.bashrc}}

\par Le fichier \texttt{.bashrc} contiendra l'ensemble des variables d'environnement essentielles ) Hadoop. Il est nécessaire qu'il soit lu. Pour ce faire, rappelons que lors de l'ouverture d'un shell interactif, certains fichiers sont automatiquement lus. Entre autres le fichier \texttt{.bash\_profile}. L'idée est de mettre un lien dans ce fichier vers notre fichier \texttt{.bashrc}. Vérifiez si les fichiers existent déjà. Le cas échéant, placez-vous dans \texttt{\$HOME}, et exécutez les commandes suivantes dans un Terminal :

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ cd $HOME
ThiDiff:~ hduser$ mkdir .bashrc
ThiDiff:~ hduser$ mkdir .bash_profile
\end{minted}

\par Dans le fichier \texttt{.bash\_profile} ajoutez ces quelques lignes :

\begin{minted}[frame=single,linenos,mathescape]{bash}
if [ -f .bashrc ]; then
. ~/.bashrc
fi
\end{minted}

\par Ensuite, le fichier \texttt{.bashrc} devra contenir au final les lignes ci-dessous :

\begin{minted}[frame=single,linenos,mathescape]{bash}
# Path to Java configuration
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_21.jdk
		 /Contents/Home

# Hadoop environment variables
export HADOOP_HOME=/usr/local/hadoop

# Add Hadoop bin/ dir to PATH Hadoop autocompletion commands
export PATH=$HADOOP_HOME/bin$PATH
export PATH=$HADOOP_HOME/sbin:$PATH
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
\end{minted}

\par Pour fonctionner, Hadoop a recours à Java, c'est pourquoi \texttt{JAVA\_HOME} est défini. Les autres variables définissent les dossiers sur lesquels Hadoop viendra chercher les fichiers de configuration.

\subsection{Le fichier \texttt{hadoop-env.sh}}

\par Ce fichier contient les variables d'environnement nécessaires à Hadoop. Pour notre installation, seule la variable \texttt{JAVA\_HOME} est nécessaire. La commande \texttt{cat} \texttt{\$(/usr/libexec/\\java\_home)} renvoie le dossier contenant l'ensemble des fichiers propres à Java.

\par Le fichier \texttt{hadoop-env.sh} contient au final :

\begin{minted}[frame=single,mathescape]{bash}
# The java implementation to use. Required.
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_21.jdk
		 /Contents/Home
\end{minted}

\subsection{Les fichiers \texttt{*-site.xml}}

\par Les trois fichiers \texttt{*-site.xml} permettent de configurer le dossier où Hadoop stock les fichiers de données, les ports utilisés, le nombre de réplication des blocs, etc.

\subsubsection{\texttt{core-site.xml}}

\par Ce fichier XML contient les informations générales de Hadoop. Entre autres, il définit le dossier dans lequel Hadoop stockera les données temporaires lors de l'exécution des tâches. Il définit aussi le nom et le port du système de fichiers qui a rendu célèbre Hadoop : HDFS (\emph{Hadoop Distributed File System}).

\begin{minted}[frame=single,linenos,mathescape]{xml}
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/app/hadoop/tmp</value>
    <description>Dossier contenant les fichiers temporaires generes
    par Hadoop.
    </description>
  </property>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://localhost:54310</value>
  </property>
</configuration>
\end{minted}

\par \texttt{/app/hadoop/tmp} est le dossier contenant les données temporaires stockées par Hadoop aussi bien pour le système de fichier local que HDFS. Créez ce dossier et donnez à l'utilisateur \texttt{hduser} les droits d'accès en 750 :

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ sudo mkdir -p /app/hadoop/tmp
ThiDiff:~ hduser$ sudo chown hduser /app/hadoop/tmp
ThiDiff:~ hduser$ sudo chmod 750 /app/hadoop/tmp
\end{minted}

\par Ne pas donner l'intégralité de ces droits à l'utilisateur \texttt{hduser}produira une exception \texttt{java.io.Exception} lors du formatage du \mathtt{NameNode} (cf. partie~\ref{sec:format-nn}).

\subsubsection{\texttt{mapred-site.xml}}
\label{sec:mapred-site.xml}

\par Rappelons-le, Hadoop, dans ses versions 0.x et 1.x, a deux principales composantes : HDFS et MapReduce. Ce fichier permet de configurer le deuxième point et plus particulièrement le \texttt{JobTracker} qui est le service d'Hadoop permettant de suivre les tâches. Pour cela on lui attribut un port sur lequel, par le biais d'une interface web on lira les informations concernant les jobs. Ce port peut être choisi de façon quelconque. Il faut de même s'assurer que celui-ci est libre. Ce qui peut se vérifier avec la commande \texttt{netstat}.

\par Le fichier \texttt{mapred-site.xml} doit contenir au final :

\begin{minted}[frame=single,linenos,mathescape]{xml}
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:54311</value>
  </property>
</configuration>
\end{minted}

\subsubsection{\texttt{hdfs-site.xml}}
\label{sec:hdfs-site.xml}

\par Ce dernier fichier définit les propriétés relatives à HDFS. On y définit particulièrement le nombre de réplications des blocs. La valeur par défaut est 2.

\begin{minted}[frame=single,linenos,mathescape]{xml}
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
\end{minted}

\par La configuration basique d'Hadoop en mode \emph{Single-Node} ne nécessite que la modification des fichiers mentionnés précédemment. Pour le mode \emph{Multi-Node} nous verrons que les fichiers \texttt{/conf/masters} et \texttt{/conf/slaves} auront leur importance et que maîtres et esclaves sont configurés différemment. Reportez-vous à la partie~\ref{sec:hadoop-2.2} pour de plus amples détails.

\subsection{Formatage du NameNode}
\label{sec:format-nn}

\par La dernière étape restante avant de pouvoir lancer des jobs Hadoop est de formater le NameNode. Ce service Hadoop est la pièce maîtresse de HDFS en ce qu'il conserve la cartographie des blocs des fichiers HDFS au sein des différents DataNodes. Dans notre cas de figure (\emph{Single-Node}), un seul DataNode étant lancé, nous pouvons être certains que l'ensemble des données y sont stockés. Dans le cas plus générale, les blocs constituant les fichiers HDFS sont répartis au sein des divers DataNodes en tenant en compte le nombre de réplications paramétré.

\par Le formatage du NameNode permet d'effacer l'ensemble des données de HDFS. C'est équivalent à un RAZ. Cette étape n'est à réaliser qu'une seule fois lors de la mise en place de votre cluster Hadoop sous risque de perdre toutes les données HDFS préalablement chargées.

\begin{minted}[frame=single,linenos,mathescape]{bash}
ThiDiff:~ hduser$ $HADOOP_HOME/bin/hadoop namenode -format
14/06/01 00:18:33 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG: host = ordinatrthidiff/192.168.1.66
STARTUP_MSG: args = [-format]
STARTUP_MSG: version = 1.2.1
STARTUP_MSG: build = https://svn.apache.org/repos/asf/hadoop/common/
		     branches/branch-1.2 -r 1503152; compiled by 'mattf'
		     on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG: java = 1.7.0_21
************************************************************/
14/06/01 00:18:35 INFO util.GSet: Computing capacity for map BlocksMap
14/06/01 00:18:35 INFO util.GSet: VM type       = 64-bit
14/06/01 00:18:35 INFO util.GSet: 2.0% max memory = 1013645312
14/06/01 00:18:35 INFO util.GSet: capacity      = 2^21 = 2097152 entries
14/06/01 00:18:35 INFO util.GSet: recommended=2097152, actual=2097152
14/06/01 00:18:36 INFO namenode.FSNamesystem: fsOwner=Hadoop
14/06/01 00:18:36 INFO namenode.FSNamesystem: supergroup=supergroup
14/06/01 00:18:36 INFO namenode.FSNamesystem: isPermissionEnabled=true
[...]
14/06/01 00:18:38 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ordinatrthidiff/192.168.1.66
************************************************************/
\end{minted}

%14/06/01 00:18:36 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
%14/06/01 00:18:36 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
%14/06/01 00:18:36 INFO namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
%14/06/01 00:18:36 INFO namenode.NameNode: Caching file names occuring more than 10 times 
%14/06/01 00:18:38 INFO common.Storage: Image file /app/hadoop/tmp/dfs/name/current/fsimage of size 112 bytes saved in 0 seconds.
%14/06/01 00:18:38 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/app/hadoop/tmp/dfs/name/current/edits
%14/06/01 00:18:38 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/app/hadoop/tmp/dfs/name/current/edits
%14/06/01 00:18:38 INFO common.Storage: Storage directory /app/hadoop/tmp/dfs/name has been successfully formatted.

\par Globalement, les étapes du formatage sont les suivantes :

\begin{itemize}
\item lancement du \texttt{NameNode};
\item formatage;
\item arrêt du \texttt{NameNode}.
\end{itemize}

\par Hadoop est désormais configuré. L'étape suivante consiste à lancer les différents services Hadoop.

\subsection{Lancement des services Hadoop}
\label{sec:start-1.x-demons}

\par Avant le lancement des services Hadoop, vous devez vous connecter en SSH au \texttt{localhost}.

\par Il suffit ensuite de lancer le script shell fourni dans le dossier Hadoop pour lancer les services :

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ ssh localhost
ThiDiff:~ hduser$ start-all.sh
starting namenode, logging to /usr/local/hadoop/libexec/../logs/hadoop-
Hadoop-namenode-ordinatrthidiff.out
localhost: starting datanode, logging to /usr/local/hadoop/libexec/../
logs/hadoop-Hadoop-datanode-ordinatrthidiff.out
localhost: starting secondarynamenode, logging to /usr/local/hadoop/
libexec/../logs/hadoop-Hadoop-secondarynamenode-ordinatrthidiff.out
starting jobtracker, logging to /usr/local/hadoop/libexec/../logs/hadoop-
Hadoop-jobtracker-ordinatrthidiff.out
localhost: starting tasktracker, logging to /usr/local/hadoop/libexec/..
/logs/hadoop-Hadoop-tasktracker-ordinatrthidiff.out
\end{minted}

\par On voit sur la sortie que le \texttt{NameNode}, le \texttt{DataNode}, le \texttt{SecondaryNameNode}, le \texttt{JobTracker} et le \texttt{TaskTracker} se sont bien lancés. Cependant il est bon de vérifier leur état à l'aide de la commande \texttt{jps} (\texttt{Java Virtual Machine Process Status Tool}).

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ jps
10649 DataNode
10891 TaskTracker
10560 NameNode
10803 JobTracker
11087 Jps
10737 SecondaryNameNode
\end{minted}

\par Nous sommes désormais sûrs que les services Hadoop se sont lancés correctement. Il se peut que \mathtt{NameNode} ou le \mathtt{DataNode} ne se lancent pas. Dans ce cas la solution la plus radicale et la plus efficace consiste à formater à nouveau le \mathtt{NameNode}. Pour ce faire, vous devez arrêter les services et suivre la démarche détaillée précédemment.

\subsection{Arrêt des services Hadoop}
\label{sec:arret-service-hadoop}

\par L'arrêt des services Hadoop s'effectue avec :

\begin{minted}[frame=single,mathescape]{bash}
ThiDiff:~ hduser$ stop-all.sh
stopping jobtracker
localhost: stopping tasktracker
stopping namenode
localhost: stopping datanode
localhost: stopping secondarynamenode
\end{minted}

\par Contrairement au lancement où certains services peuvent ne pas se lancer, la commande \texttt{stop-all.sh} met radicalement fin à ces derniers.

\section{WordCount}
\label{sec:ex-wordcount}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "CompteRendu"
%%% End: 
